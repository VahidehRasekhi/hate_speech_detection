{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10afbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814055f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31925</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate isz youuu</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31926</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31927</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31928</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>sikh temple vandalised calgary wso condemns act</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31929</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank follow</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31930 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0  father dysfunctional selfish drags kids dysfun...   \n",
       "1          2      0  thanks lyft credit use cause offer wheelchair ...   \n",
       "2          3      0                                     bihday majesty   \n",
       "3          4      0                        model love u take u time ur   \n",
       "4          5      0                      factsguide society motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31925  31958      0                                      ate isz youuu   \n",
       "31926  31959      0  see nina turner airwaves trying wrap mantle ge...   \n",
       "31927  31960      0    listening sad songs monday morning otw work sad   \n",
       "31928  31961      1    sikh temple vandalised calgary wso condemns act   \n",
       "31929  31962      0                                       thank follow   \n",
       "\n",
       "       length  count  \n",
       "0          55      7  \n",
       "1          77     11  \n",
       "2          14      2  \n",
       "3          27      7  \n",
       "4          29      3  \n",
       "...       ...    ...  \n",
       "31925      13      3  \n",
       "31926      93     14  \n",
       "31927      47      8  \n",
       "31928      47      7  \n",
       "31929      12      2  \n",
       "\n",
       "[31930 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets=pd.read_csv('../data/Dataset 1/clean_train_tweets.csv', encoding=\"utf-8\")\n",
    "train_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0429e9f",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1daac195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using scikit-learn to transform text into token count vector\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer(\n",
    "    token_pattern = r\"[a-z]+\", \n",
    "    ngram_range = (1,1), #ngram_range (1,1)= only unigrams, (1,2)=unigrams and bigrams, (2,2)=bigrams\n",
    "    lowercase = True,\n",
    "    min_df = 1, #min_df=1 is the default, means ignore terms that appear in less than 1 document/text.\n",
    "    max_df = 1.0 #max_df=1.0 is the default, means ignore terms that appear in more than 100% of the documents/texts.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345f92d",
   "metadata": {},
   "source": [
    "### Splitting the train dataset into train and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6997f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to test perfomarnce against the development set, we can split the training dataset into train and dev\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5bce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15% of train_tweets will be in dev\n",
    "train, dev= train_test_split(train_tweets, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b51f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27140x34039 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 200746 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train['tweet'].values\n",
    "X_train_vect = count_vector.fit_transform(X_train) #fitting CountVectorizer, transforms trainging data into \n",
    "                                                    #matrix representing token counts \n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915210e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a PredefinedSplit\n",
    "\n",
    "X_train = train['tweet'].values\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_dev = dev['tweet'].values\n",
    "y_dev = dev['label'].values\n",
    "\n",
    "X = np.hstack([X_train, X_dev])\n",
    "y = np.hstack([y_train, y_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89cbc367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    27140\n",
       " 0.0     4790\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign 0 to items that are in dev and -1 for the rest\n",
    "split_train_dev= np.zeros(shape=y.shape)\n",
    "split_train_dev[:y_train.shape[0]] = -1\n",
    "pd.value_counts(split_train_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0dcd3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02901ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit,GridSearchCV\n",
    "\n",
    "ps = PredefinedSplit(split_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c836a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vect_1 = CountVectorizer(\n",
    "    token_pattern = r\"[a-z]+\", \n",
    "    ngram_range = (1,1),\n",
    "    lowercase = True,\n",
    "    min_df = 1,\n",
    "    max_df = 1.0\n",
    ")\n",
    "\n",
    "vect_2 = TfidfVectorizer(\n",
    "    token_pattern = r\"[a-z]+\", \n",
    "    ngram_range = (1,1),\n",
    "    lowercase = True,\n",
    "    min_df = 1,\n",
    "    max_df = 1.0\n",
    ")\n",
    "\n",
    "select = SelectPercentile(score_func=chi2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=2)\n",
    "\n",
    "pipe = Pipeline([(\"vect\", vect_1), (\"select\", select), (\"clf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70c245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 30 candidates, totalling 30 fits\n",
      "{'vect__ngram_range': (1, 1), 'vect__min_df': 10, 'vect': TfidfVectorizer(min_df=10, token_pattern='[a-z]+'), 'select__percentile': 50, 'clf__n_estimators': 100, 'clf__max_depth': 2, 'clf__class_weight': 'balanced'}\n",
      "0.5121602288984264\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'vect':[vect_1, vect_2],\n",
    "    'vect__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "    'vect__min_df':[1, 2, 5, 10, 20],\n",
    "    'select__percentile':[1, 2, 5, 10, 20, 50],\n",
    "    'clf__n_estimators':[10, 20, 50, 100],\n",
    "    'clf__max_depth':[1, 2, 5, 10],\n",
    "    'clf__class_weight':[None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(pipe, param_grid, n_iter=30, scoring='f1', n_jobs=3, cv=ps, verbose=2)\n",
    "rs.fit(X, y)\n",
    "print(rs.best_params_)\n",
    "print(rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9b632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4251,  176],\n",
       "       [ 182,  181]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = rs.best_estimator_.predict(X_dev)\n",
    "confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "#confusion matrix for random forest\n",
    "                                     #TP 4251 -- FP 176  #positives are non_offensive\n",
    "                                    # FN 182  -- TN 181  #negatives are offensive\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb08ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4427\n",
      "           1       0.51      0.50      0.50       363\n",
      "\n",
      "    accuracy                           0.93      4790\n",
      "   macro avg       0.73      0.73      0.73      4790\n",
      "weighted avg       0.92      0.93      0.92      4790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a47b2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252609603340293"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_dev==y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20e7564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dde3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3264c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c832abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
